#
# Current best known config for i.i.d. pre-training an ANML-like model on Mini-ImageNet.
#

# Dataset
dataset: miniimagenet
train_size: 500

# Training Configuration
train_method: iid
batch_size: 256
epochs: 30
seed: 1

# Model Architecture
model: classifier
model_args:
  encoder: convnet
  encoder_args:
    num_blocks: 4
    num_filters: 256
  classifier: linear-classifier
  classifier_args: {num_classes: 1000}

# Optimization
optimizer: SGD
optimizer_args:
  lr: 0.1
  momentum: 0.9
  weight_decay: 0.0001
lr_scheduler: StepLR
lr_scheduler_args:
  step_size: 10
  gamma: 0.1

# Evaluation
save_freq: 125
eval_steps: [1000, 2000]
eval:
  - no-sgd: !include eval-inet-zero-shot.yml
  - olft: !include eval-sweep-inet-1FC.yml
  - unfrozen: !include eval-sweep-inet-unfrozen.yml
  - lstsq-unfrozen: !include eval-sweep-inet-lstsq-unfrozen.yml
  - iid-olft: !include eval-sweep-inet-iid-1FC.yml
  - iid-unfrozen: !include eval-sweep-inet-iid-unfrozen.yml
  - iid-lstsq-unfrozen: !include eval-sweep-inet-iid-lstsq-unfrozen.yml

